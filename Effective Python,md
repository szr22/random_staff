# 1. Pythonic Thinking

## ITEM 1: KNOW WHICH VERSION OF PYTHON YOU’RE USING

## ITEM 2: FOLLOW THE PEP 8 STYLE GUIDE
1. Whitespace
2. Naming
3. Expressions and Statements

## ITEM 3: KNOW THE DIFFERENCES BETWEEN BYTES, STR, AND UNICODE
1. In Python 3, bytes and str instances are never equivalent—not even the empty string
2. The second issue is that in Python 3, operations involving file handles (returned by the open built-in function) default to UTF-8 encoding

In Python 3, bytes contains sequences of 8-bit values, str contains sequences of Unicode characters

## ITEM 4: WRITE HELPER FUNCTIONS INSTEAD OF COMPLEX EXPRESSIONS

## ITEM 5: KNOW HOW TO SLICE SEQUENCES
somelist[start:end], where start is inclusive and end is exclusive

## ITEM 6: AVOID USING START, END, AND STRIDE IN A SINGLE SLICE

## ITEM 7: USE LIST COMPREHENSIONS INSTEAD OF MAP AND FILTER

## ITEM 8: AVOID MORE THAN TWO EXPRESSIONS IN LIST COMPREHENSIONS

## ITEM 9: CONSIDER GENERATOR EXPRESSIONS FOR LARGE COMPREHENSIONS

## ITEM 10: PREFER ENUMERATE OVER RANGE

## ITEM 11: USE ZIP TO PROCESS ITERATORS IN PARALLEL

## ITEM 12: AVOID ELSE BLOCKS AFTER FOR AND WHILE LOOPS

## ITEM 13: TAKE ADVANTAGE OF EACH BLOCK IN TRY/EXCEPT/ELSE/FINALLY
try/except/else/finally

# 2. Functions

## ITEM 14: PREFER EXCEPTIONS TO RETURNING NONE
```
def divide(a, b):
    try:
        return True, a / b
    except ZeroDivisionError:
        return False, None
```
or 
```
def divide(a, b):
    try:
        return a / b
    except ZeroDivisionError as e:
        raise ValueError('Invalid inputs') from e
```

## ITEM 15: KNOW HOW CLOSURES INTERACT WITH VARIABLE SCOPE
Bad:
'''
def sort_priority(values, group):
    def helper(x):
        if x in group:
            return (0, x)
        return (1, x)
    values.sort(key=helper)

numbers = [8, 3, 1, 2, 5, 4, 7, 6]
group = {2, 3, 5, 7}
sort_priority(numbers, group)
print(numbers)
'''

Good:
'''
def sort_priority3(numbers, group):
    found = False
    def helper(x):
        nonlocal found
        if x in group:
            found = True
            return (0, x)
        return (1, x)
    numbers.sort(key=helper)
    return found
'''

Better:
'''
class Sorter(object):
    def __init__(self, group):
        self.group = group
        self.found = False

    def __call__(self, x):
        if x in self.group:
            self.found = True
            return (0, x)
        return (1, x)

sorter = Sorter(group)
numbers.sort(key=sorter)
'''

note: Python has specific rules for comparing tuples. It first compares items in index zero, then index one, then index two, and so on. This is why the return value from the helper closure causes the sort order to have two distinct groups.

variable resolve order
1. The current function’s scope
2. Any enclosing scopes (like other containing functions)
3. The scope of the module that contains the code (also called the global scope)
4. The built-in scope (that contains functions like len and str)

5. (exception) If none of these places have a defined variable with the referenced name, then a NameError exception is raised.

## ITEM 16: CONSIDER GENERATORS INSTEAD OF RETURNING LISTS
good
'''
def index_words_iter(text):
    if text:
        yield 0
    for index, letter in enumerate(text):
        if letter == ' ':
            yield index + 1
result = list(index_words_iter(address))

'''
better
'''
def index_file(handle):
    offset = 0
    for line in handle:
        if line:
            yield offset
        for letter in line:
            offset += 1
            if letter == ' ':
               yield offset
'''

## ITEM 17: BE DEFENSIVE WHEN ITERATING OVER ARGUMENTS
Good
pass in a lambda expression that calls the generator and produces a new iterator each time.
'''
def normalize_func(get_iter):
    total = sum(get_iter())   # New iterator
    result = []
    for value in get_iter():  # New iterator
        percent = 100 * value / total
        result.append(percent)
    return result
'''

Better
'''
class ReadVisits(object):
    def __init__(self, data_path):
        self.data_path = data_path

    def __iter__(self):
        with open(self.data_path) as f:
            for line in f:
                yield int(line)

visits = ReadVisits(path)
percentages = normalize(visits)
print(percentages)
'''

## ITEM 18: REDUCE VISUAL NOISE WITH VARIABLE POSITIONAL ARGUMENTS
Good
'''
def log(message, *values):  # The only difference
    if not values:
        print(message)
    else:
        values_str = ', '.join(str(x) for x in values)
        print('%s: %s' % (message, values_str))

log('My numbers are', 1, 2)
log('Hi there')  # Much better
'''

Better
'''
def my_generator():
    for i in range(10):
        yield i

def my_func(*args):
    print(args)

it = my_generator()
my_func(*it)
'''

## ITEM 19: PROVIDE OPTIONAL BEHAVIOR WITH KEYWORD ARGUMENTS

## ITEM 20: USE NONE AND DOCSTRINGS TO SPECIFY DYNAMIC DEFAULT ARGUMENTS
Default arguments are only evaluated once: during function definition at module load time. This can cause odd behaviors for dynamic values (like {} or [])
Use None as the default value for keyword arguments that have a dynamic value. Document the actual default behavior in the function’s docstring.

## ITEM 21: ENFORCE CLARITY WITH KEYWORD-ONLY ARGUMENTS

# 3. Classes and Inheritance
inheritance, polymorphism, and encapsulation

## ITEM 22: PREFER HELPER CLASSES OVER BOOKKEEPING WITH DICTIONARIES AND TUPLES
Avoid making dictionaries with values that are other dictionaries or long tuples.
Use namedtuple for lightweight, immutable data containers before you need the flexibility of a full class.
Move your bookkeeping code to use multiple helper classes when your internal state dictionaries get complicated.

## ITEM 23: ACCEPT FUNCTIONS FOR SIMPLE INTERFACES INSTEAD OF CLASSES
Instead of defining and instantiating classes, functions are often all you need for simple interfaces between components in Python.
References to functions and methods in Python are first class, meaning they can be used in expressions like any other type.
The __call__ special method enables instances of a class to be called like plain Python functions.
When you need a function to maintain state, consider defining a class that provides the __call__ method instead of defining a stateful closure

## ITEM 24: USE @CLASSMETHOD POLYMORPHISM TO CONSTRUCT OBJECTS GENERICALLY
'''
def generate_inputs(data_dir):
    for name in os.listdir(data_dir):
        yield PathInputData(os.path.join(data_dir, name))

def create_workers(input_list):
    workers = []
    for input_data in input_list:
        workers.append(LineCountWorker(input_data))
    return workers

def execute(workers):
    threads = [Thread(target=w.map) for w in workers]
    for thread in threads: thread.start()
    for thread in threads: thread.join()

    first, rest = workers[0], workers[1:]
    for worker in rest:
        first.reduce(worker)
    return first.result
    
def mapreduce(data_dir):
    inputs = generate_inputs(data_dir)
    workers = create_workers(inputs)
    return execute(workers)
'''
class
'''
class GenericInputData(object):
    def read(self):
        raise NotImplementedError

    @classmethod
    def generate_inputs(cls, config):
        raise NotImplementedError

class PathInputData(GenericInputData):
    # ...
    def read(self):
        return open(self.path).read()

    @classmethod
    def generate_inputs(cls, config):
        data_dir = config['data_dir']
        for name in os.listdir(data_dir):
            yield cls(os.path.join(data_dir, name))

class GenericWorker(object):
    # ...
    def map(self):
        raise NotImplementedError

    def reduce(self, other):
        raise NotImplementedError

    @classmethod
    def create_workers(cls, input_class, config):
        workers = []
        for input_data in input_class.generate_inputs(config):
            workers.append(cls(input_data))
        return workers
'''

Python only supports a single constructor per class, the __init__ method
Use @classmethod to define alternative constructors for your classes.
Use class method polymorphism to provide generic ways to build and connect concrete subclasses.

## ITEM 25: INITIALIZE PARENT CLASSES WITH SUPER
Python’s standard method resolution order (MRO) solves the problems of superclass initialization order and diamond inheritance.
Always use the super built-in function to initialize parent classes.

## ITEM 26: USE MULTIPLE INHERITANCE ONLY FOR MIX-IN UTILITY CLASSES
Avoid using multiple inheritance if mix-in classes can achieve the same outcome.
Use pluggable behaviors at the instance level to provide per-class customization when mix-in classes may require it.
Compose mix-ins to create complex functionality from simple behaviors.

## ITEM 27: PREFER PUBLIC ATTRIBUTES OVER PRIVATE ONES
Private attributes aren’t rigorously enforced by the Python compiler.
Plan from the beginning to allow subclasses to do more with your internal APIs and attributes instead of locking them out by default.
Use documentation of protected fields to guide subclasses instead of trying to force access control with private attributes.
Only consider using private attributes to avoid naming conflicts with subclasses that are out of your control.

## ITEM 28: INHERIT FROM COLLECTIONS.ABC FOR CUSTOM CONTAINER TYPES
Inherit directly from Python’s container types (like list or dict) for simple use cases.
Beware of the large number of methods required to implement custom container types correctly.
Have your custom container types inherit from the interfaces defined in '''collections.abc''' to ensure that your classes match required interfaces and behaviors.

4. Metaclasses and Attributes
## ITEM 29: USE PLAIN ATTRIBUTES INSTEAD OF GET AND SET METHODS
Define new class interfaces using simple public attributes, and avoid set and get methods.
Use @property to define special behavior when attributes are accessed on your objects, if necessary.
Follow the rule of least surprise and avoid weird side effects in your @property methods.
Ensure that @property methods are fast; do slow or complex work using normal methods.

## ITEM 30: CONSIDER @PROPERTY INSTEAD OF REFACTORING ATTRIBUTES
Use @property to give existing instance attributes new functionality.
Make incremental progress toward better data models by using @property.
Consider refactoring a class and all call sites when you find yourself using @property too heavily.

## ITEM 31: USE DESCRIPTORS FOR REUSABLE @PROPERTY METHODS
Reuse the behavior and validation of @property methods by defining your own descriptor classes.
Use WeakKeyDictionary to ensure that your descriptor classes don’t cause memory leaks.
Don’t get bogged down trying to understand exactly how __getattribute__ uses the descriptor protocol for getting and setting attributes.

## ITEM 32: USE __GETATTR__, __GETATTRIBUTE__, AND __SETATTR__ FOR LAZY ATTRIBUTES
Use __getattr__ and __setattr__ to lazily load and save attributes for an object.
Understand that __getattr__ only gets called once when accessing a missing attribute, whereas __getattribute__ gets called every time an attribute is accessed.
Avoid infinite recursion in __getattribute__ and __setattr__ by using methods from super() (i.e., the object class) to access instance attributes directly.

## ITEM 33: VALIDATE SUBCLASSES WITH METACLASSES
Use metaclasses to ensure that subclasses are well formed at the time they are defined, before objects of their type are constructed.
Metaclasses have slightly different syntax in Python 2 vs. Python 3.
The __new__ method of metaclasses is run after the class statement’s entire body has been processed.

## ITEM 34: REGISTER CLASS EXISTENCE WITH METACLASSES
Class registration is a helpful pattern for building modular Python programs.
Metaclasses let you run registration code automatically each time your base class is subclassed in a program.
Using metaclasses for class registration avoids errors by ensuring that you never miss a registration call.

## ITEM 35: ANNOTATE CLASS ATTRIBUTES WITH METACLASSES
Metaclasses enable you to modify a class’s attributes before the class is fully defined.
Descriptors and metaclasses make a powerful combination for declarative behavior and runtime introspection.
You can avoid both memory leaks and the weakref module by using metaclasses along with descriptors.


5. Concurrency and Parallelism
## ITEM 36: USE SUBPROCESS TO MANAGE CHILD PROCESSES
Use the subprocess module to run child processes and manage their input and output streams.
Child processes run in parallel with the Python interpreter, enabling you to maximize your CPU usage.
Use the timeout parameter with communicate to avoid deadlocks and hanging child processes.

## ITEM 37: USE THREADS FOR BLOCKING I/O, AVOID FOR PARALLELISM
Python threads can’t run bytecode in parallel on multiple CPU cores because of the global interpreter lock (GIL).
Python threads are still useful despite the GIL because they provide an easy way to do multiple things at seemingly the same time.
Use Python threads to make multiple system calls in parallel. This allows you to do blocking I/O at the same time as computation.

## ITEM 38: USE LOCK TO PREVENT DATA RACES IN THREADS
Even though Python has a global interpreter lock, you’re still responsible for protecting against data races between the threads in your programs.
Your programs will corrupt their data structures if you allow multiple threads to modify the same objects without locks.
The Lock class in the threading built-in module is Python’s standard mutual exclusion lock implementation.

## ITEM 39: USE QUEUE TO COORDINATE WORK BETWEEN THREADS
Pipelines are a great way to organize sequences of work that run concurrently using multiple Python threads.
Be aware of the many problems in building concurrent pipelines: busy waiting, stopping workers, and memory explosion.
The Queue class has all of the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining.

## ITEM 40: CONSIDER COROUTINES TO RUN MANY FUNCTIONS CONCURRENTLY
'''
ALIVE = '*'
EMPTY = '-'
Query = namedtuple('Query', ('y', 'x'))
def count_neighbors(y, x):
    n_ = yield Query(y + 1, x + 0)  # North
    ne = yield Query(y + 1, x + 1)  # Northeast
    # Define e_, se, s_, sw, w_, nw ...
    # ...
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count
it = count_neighbors(10, 5)
q1 = next(it)                  # Get the first query
print('First yield: ', q1)
q2 = it.send(ALIVE)            # Send q1 state, get q2
print('Second yield:', q2)
q3 = it.send(ALIVE)            # Send q2 state, get q3
# ...
try:
    count = it.send(EMPTY)     # Send q8 state, retrieve count
except StopIteration as e:
    print('Count: ', e.value)  # Value from return statement
>>>
First yield:  Query(y=11, x=5)
Second yield: Query(y=11, x=6)
...
Count:  2


Transition = namedtuple('Transition', ('y', 'x', 'state'))


def game_logic(state, neighbors):
    # ...

def step_cell(y, x):
    state = yield Query(y, x)
    neighbors = yield from count_neighbors(y, x)
    next_state = game_logic(state, neighbors)
    yield Transition(y, x, next_state)
    
def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY     # Die: Too few
        elif neighbors > 3:
            return EMPTY     # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE     # Regenerate
    return state
'''

Coroutines provide an efficient way to run tens of thousands of functions seemingly at the same time.
Within a generator, the value of the yield expression will be whatever value was passed to the generator’s send method from the exterior code.
Coroutines give you a powerful tool for separating the core logic of your program from its interaction with the surrounding environment.
Python 2 doesn’t support yield from or returning values from generators.

## ITEM 41: CONSIDER CONCURRENT.FUTURES FOR TRUE PARALLELISM
Moving CPU bottlenecks to C-extension modules can be an effective way to improve performance while maximizing your investment in Python code. However, the cost of doing so is high and may introduce bugs.
The multiprocessing module provides powerful tools that can parallelize certain types of Python computation with minimal effort.
The power of multiprocessing is best accessed through the concurrent.futures built-in module and its simple ProcessPoolExecutor class.
The advanced parts of the multiprocessing module should be avoided because they are so complex.


